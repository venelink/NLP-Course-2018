{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to NLP course (2017-2018).\n",
    "\n",
    "Notebook 1: Introduction to NLTK.\n",
    "by Venelin Kovatchev, University of Barcelona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the main nltk library\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download all the data for the nltk\n",
    "# This step downloads a big chunk of data. \n",
    "# Do this at home on a stable network connection\n",
    "# DO NOT DO THIS AT CLASS !\n",
    "\n",
    "nltk.download() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gutenberg Project contains over 25,000 books in a digital format. A small portion of it is available in NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'austen-emma.txt', u'austen-persuasion.txt', u'austen-sense.txt', u'bible-kjv.txt', u'blake-poems.txt', u'bryant-stories.txt', u'burgess-busterbrown.txt', u'carroll-alice.txt', u'chesterton-ball.txt', u'chesterton-brown.txt', u'chesterton-thursday.txt', u'edgeworth-parents.txt', u'melville-moby_dick.txt', u'milton-paradise.txt', u'shakespeare-caesar.txt', u'shakespeare-hamlet.txt', u'shakespeare-macbeth.txt', u'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "# Load the gutenberg corpus\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "# Check the different files available in the gutenberg corpus\n",
    "print(gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corpus is available in three different formats: raw, tokenized and sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assign three different versions of the ``emma'' to variables\n",
    "emma_raw = gutenberg.raw('austen-emma.txt')\n",
    "emma_words = gutenberg.words('austen-emma.txt')\n",
    "emma_sents = gutenberg.sents('austen-emma.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect different corpora formats.\n",
    "- most corpora is available in \"raw format\"; a single string\n",
    "- corpora in \"tokenized\" format contains linguistic units; a list of strings\n",
    "- corpora in \"sentence\" format contains two linguistic levels; a list of lists of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw corpus\n",
      "----------------\n",
      "Raw corpus format: [Emma by J\n",
      "Raw corpus length: 887071\n",
      "\n",
      "Tokenized corpus\n",
      "----------------\n",
      "Tokenized corpus format: [u'[', u'Emma', u'by', u'Jane', u'Austen', u'1816', u']', u'VOLUME', u'I', u'CHAPTER']\n",
      "Tokenized corpus length: 192427\n",
      "\n",
      "Sentence corpus\n",
      "----------------\n",
      "Sentence corpus format: [[u'[', u'Emma', u'by', u'Jane', u'Austen', u'1816', u']'], [u'VOLUME', u'I'], [u'CHAPTER', u'I']]\n",
      "Sentence corpus length: 7752\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw corpus\\n----------------\")\n",
    "print(\"Raw corpus format: {0}\".format(emma_raw[:10]))\n",
    "print(\"Raw corpus length: {0}\".format(len(emma_raw)))\n",
    "print(\"\\nTokenized corpus\\n----------------\")\n",
    "print(\"Tokenized corpus format: {0}\".format(emma_words[:10]))\n",
    "print(\"Tokenized corpus length: {0}\".format(len(emma_words)))\n",
    "print(\"\\nSentence corpus\\n----------------\")\n",
    "print(\"Sentence corpus format: {0}\".format(emma_sents[:3]))\n",
    "print(\"Sentence corpus length: {0}\".format(len(emma_sents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linguistic processing is a standard step in many tasks. It adds additional (linguistic) information to the corpus, which can be used in the following steps in a pipeline or as features in a ML system.\n",
    "\n",
    "The Brown corpus in NLTK is annotated with morphological categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'adventure', u'belles_lettres', u'editorial', u'fiction', u'government', u'hobbies', u'humor', u'learned', u'lore', u'mystery', u'news', u'religion', u'reviews', u'romance', u'science_fiction']\n",
      "\n",
      "Part of speech tagged tokenized corpus: [(u'The', u'AT'), (u'Fulton', u'NP-TL'), (u'County', u'NN-TL'), (u'Grand', u'JJ-TL'), (u'Jury', u'NN-TL'), (u'said', u'VBD'), (u'Friday', u'NR'), (u'an', u'AT'), (u'investigation', u'NN'), (u'of', u'IN')]\n"
     ]
    }
   ],
   "source": [
    "# Import the Brown corpus\n",
    "from nltk.corpus import brown\n",
    "\n",
    "# Print the available categories\n",
    "print(brown.categories())\n",
    "\n",
    "# Load the tagged version of \"news\"\n",
    "brown_twords = brown.tagged_words(categories='news')\n",
    "\n",
    "print(\"\\nPart of speech tagged tokenized corpus: {0}\".format(brown_twords[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PENN Treebank corpus in NLTK is annotated with syntactic relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syntactically parsed sentence: [Tree('S', [Tree('NP-SBJ', [Tree('NP', [Tree('NNP', ['Pierre']), Tree('NNP', ['Vinken'])]), Tree(',', [',']), Tree('ADJP', [Tree('NP', [Tree('CD', ['61']), Tree('NNS', ['years'])]), Tree('JJ', ['old'])]), Tree(',', [','])]), Tree('VP', [Tree('MD', ['will']), Tree('VP', [Tree('VB', ['join']), Tree('NP', [Tree('DT', ['the']), Tree('NN', ['board'])]), Tree('PP-CLR', [Tree('IN', ['as']), Tree('NP', [Tree('DT', ['a']), Tree('JJ', ['nonexecutive']), Tree('NN', ['director'])])]), Tree('NP-TMP', [Tree('NNP', ['Nov.']), Tree('CD', ['29'])])])]), Tree('.', ['.'])]), Tree('S', [Tree('NP-SBJ', [Tree('NNP', ['Mr.']), Tree('NNP', ['Vinken'])]), Tree('VP', [Tree('VBZ', ['is']), Tree('NP-PRD', [Tree('NP', [Tree('NN', ['chairman'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('NP', [Tree('NNP', ['Elsevier']), Tree('NNP', ['N.V.'])]), Tree(',', [',']), Tree('NP', [Tree('DT', ['the']), Tree('NNP', ['Dutch']), Tree('VBG', ['publishing']), Tree('NN', ['group'])])])])])]), Tree('.', ['.'])])]\n"
     ]
    }
   ],
   "source": [
    "# Load the Penn treebank\n",
    "from nltk.corpus import treebank\n",
    "\n",
    "# Get the id of the first sentence\n",
    "first_id = treebank.fileids()[0]\n",
    "\n",
    "# Look at the format\n",
    "print(\"Syntactically parsed sentence: {}\".format(treebank.parsed_sents(first_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Look at the format from a tree representation\n",
    "treebank.parsed_sents(first_id)[0].draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some corpora are built around a specific task. \n",
    "They have additional information (such as a label).\n",
    "\n",
    "An example of such corpus is the movie review corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories in the movie review corpus: [u'neg', u'pos']\n",
      "\n",
      "Positive review: [[u'films', u'adapted', u'from', u'comic', u'books', u'have', u'had', u'plenty', u'of', u'success', u',', u'whether', u'they', u\"'\", u're', u'about', u'superheroes', u'(', u'batman', u',', u'superman', u',', u'spawn', u')', u',', u'or', u'geared', u'toward', u'kids', u'(', u'casper', u')', u'or', u'the', u'arthouse', u'crowd', u'(', u'ghost', u'world', u')', u',', u'but', u'there', u\"'\", u's', u'never', u'really', u'been', u'a', u'comic', u'book', u'like', u'from', u'hell', u'before', u'.'], [u'for', u'starters', u',', u'it', u'was', u'created', u'by', u'alan', u'moore', u'(', u'and', u'eddie', u'campbell', u')', u',', u'who', u'brought', u'the', u'medium', u'to', u'a', u'whole', u'new', u'level', u'in', u'the', u'mid', u\"'\", u'80s', u'with', u'a', u'12', u'-', u'part', u'series', u'called', u'the', u'watchmen', u'.'], [u'to', u'say', u'moore', u'and', u'campbell', u'thoroughly', u'researched', u'the', u'subject', u'of', u'jack', u'the', u'ripper', u'would', u'be', u'like', u'saying', u'michael', u'jackson', u'is', u'starting', u'to', u'look', u'a', u'little', u'odd', u'.']]\n",
      "\n",
      "Negative review: [[u'plot', u':', u'two', u'teen', u'couples', u'go', u'to', u'a', u'church', u'party', u',', u'drink', u'and', u'then', u'drive', u'.'], [u'they', u'get', u'into', u'an', u'accident', u'.'], [u'one', u'of', u'the', u'guys', u'dies', u',', u'but', u'his', u'girlfriend', u'continues', u'to', u'see', u'him', u'in', u'her', u'life', u',', u'and', u'has', u'nightmares', u'.']]\n"
     ]
    }
   ],
   "source": [
    "# Load the corpus\n",
    "from nltk.corpus import movie_reviews\n",
    "# Check the categories\n",
    "print(\"Categories in the movie review corpus: {0}\".format(movie_reviews.categories()))\n",
    "# Load the first files of each category\n",
    "movie_pos = movie_reviews.sents(movie_reviews.fileids(\"pos\")[0])\n",
    "movie_neg = movie_reviews.sents(movie_reviews.fileids(\"neg\")[0])\n",
    "\n",
    "# Look at each of the sentences\n",
    "print(\"\\nPositive review: {0}\".format(movie_pos[:3]))\n",
    "print(\"\\nNegative review: {0}\".format(movie_neg[:3]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
