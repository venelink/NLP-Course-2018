{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Introduction to NLP course (2017-2018).\n",
    "\n",
    "Notebook 5: Chunking. Syntactic parsing.\n",
    "\n",
    "by Venelin Kovatchev, University of Barcelona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import section\n",
    "\n",
    "# Import NLTK\n",
    "import nltk\n",
    "\n",
    "# Import corps for chunking\n",
    "from nltk.corpus import conll2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "(Why) Text structure:\n",
    "\n",
    "- “The meaning of a complex expression is determined by the meanings of its constituent expressions and **the rules used to combine them**”\n",
    "    - Formal sentence structure, no semantics\n",
    "- “A dog bites a man” vs “A man bites a dog” – in a bag-of-words, these are the same\n",
    "- Compositional and non-compositional elements: “A dog bites John Smith”\n",
    "\n",
    "Parsing and generation:\n",
    "- “A Dog bites a man” -> who did what to whom (is the sentence possible at all)\n",
    "- “Dog”, “bite”, “man” -> what kind of sentences can be generated using these words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Shallow parsing (chunking):\n",
    "- Linear I-O-B structure. \n",
    "- No hierarchy. No (complex) long distance dependencies.\n",
    "- Identify constituents.\n",
    "- More computationally effective and higher accuracy.\n",
    "- Can use a familiar approach (HMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Split the conll corpus into test and train\n",
    "test_sents = conll2000.chunked_sents('test.txt')\n",
    "train_sents = conll2000.chunked_sents('train.txt')\n",
    "\n",
    "# See the format of the chunked corpus\n",
    "# Print the original format\n",
    "print(\"Chunked sentence: {}\".format(train_sents[99]))\n",
    "# Draw a tree\n",
    "train_sents[99].draw()\n",
    "# Print the I-O-B format\n",
    "print(\"Chunked sentence in I-O-B format: {}\".format(nltk.chunk.tree2conlltags(train_sents[99])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The main principle of (simplified) chunking:\n",
    "- ignore the actual word and only work with the POS tag\n",
    "- define (or train) a model that maps from sequences of POS tags to sequences of IOB tags\n",
    " \n",
    "Regex chunking:\n",
    "- POS tags and Chunk tags are relatively small closed sets\n",
    "- List of manually created (regex) rules that map from one to the other\n",
    "\n",
    "HMM chunking:\n",
    "- Train an HMM model to map from POS tag sequences to IOB tag sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Regex chunking\n",
    "# Test sentence, already POS tagged\n",
    "sentence = [(\"the\", \"DT\"), (\"little\", \"JJ\"), (\"yellow\", \"JJ\"), (\"dog\", \"NN\"), (\"barked\", \"VBD\"), (\"at\", \"IN\"),  (\"the\", \"DT\"), (\"cat\", \"NN\")]\n",
    "\n",
    "# A simple grammar to identify noun phrases\n",
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "\n",
    "# Parse the sentence\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(sentence)\n",
    "\n",
    "print (\"The result of parsing the test sentence with the manual grammar: {}\".format(result))\n",
    "print (\"The result of parsing the test sentence with the manual grammar (IOB): {}\".format(nltk.chunk.tree2conlltags(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# HMM chunker\n",
    "class unigram_chunker(nltk.ChunkParserI):\n",
    "    \n",
    "    # Initialize and train the chunker\n",
    "    def __init__(self, train_sents):\n",
    "        # Take the pos and the iob tags of the corpus\n",
    "        # Ignore the actual words, we map from pos tag to iob tag\n",
    "        train_data = [[(t,c) for w,t,c in nltk.chunk.tree2conlltags(sent)] for sent in train_sents]\n",
    "        # Train an unigram tagger from the train data\n",
    "        self.tagger = nltk.UnigramTagger(train_data)\n",
    "    \n",
    "    # Parse function\n",
    "    # Takes a corpus in POS tagged format\n",
    "    def parse(self,sentence):\n",
    "        # Take the pos tags\n",
    "        pos_tags = [pos for (word,pos) in sentence]\n",
    "        # Use the tagger to tag the modified corpus\n",
    "        tagged_pos_tags = self.tagger.tag(pos_tags)\n",
    "        # Take the chunks from the tagged corpus\n",
    "        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
    "        # Convert the output\n",
    "        conlltags = [(word, pos, chunktag) for ((word,pos),chunktag) in zip(sentence, chunktags)]\n",
    "        \n",
    "        # Return the tagged sentence\n",
    "        return nltk.chunk.conlltags2tree(conlltags)\n",
    "\n",
    "uni_chunker = unigram_chunker(train_sents)\n",
    "print (\"The performance of unigram chunker is: {}\".format(uni_chunker.evaluate(test_sents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "(Full) Syntactic parsing:\n",
    "- Assign a (hierarchical binary tree) structure to a sentence, given a grammar\n",
    "- Input: Grammar (pre-defined), sentence\n",
    "- Output: all possible trees (if any)\n",
    "\n",
    "Syntactic ambiguity (multiple parses for the same sentence)\n",
    "- Disambiguation through probabilistic grammers\n",
    "- Rule based (heuristic) disambiguation\n",
    "- Use of external resources (such as dictionaries, knowledge bases, and parsed corpora)\n",
    "\n",
    "Context free grammar:\n",
    "- sets of rules each of which expresses the ways the symbols of the language can be grouped and ordered together \n",
    "- a lexicon of words and symbols\n",
    "\n",
    "\n",
    "- terminal nodes – the lexicon of the language (actual words)\n",
    "- non-terminal nodes – generalization nodes (classes, such as POS)\n",
    "- start symbol (S)\n",
    "- derivation – a sequence of rule expansion (left to right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# A simple CFG\n",
    "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
    "  S -> NP VP\n",
    "  VP -> V NP | V NP PP\n",
    "  PP -> P NP\n",
    "  V -> \"saw\" | \"ate\" | \"walked\"\n",
    "  NP -> \"John\" | \"Mary\" | \"Bob\" | Det N | Det N PP\n",
    "  Det -> \"a\" | \"an\" | \"the\" | \"my\"\n",
    "  N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\"\n",
    "  P -> \"in\" | \"on\" | \"by\" | \"with\"\n",
    "  \"\"\")\n",
    "\n",
    "# Test sentence\n",
    "sent = \"Mary saw Bob\".split()\n",
    "\n",
    "# Parse the sentence using the grammar\n",
    "rd_parser = nltk.RecursiveDescentParser(grammar1)\n",
    "\n",
    "# Print all possible trees\n",
    "for tree in rd_parser.parse(sent):\n",
    "    print(tree)\n",
    "\n",
    "# Draw all possible trees\n",
    "for tree in rd_parser.parse(sent):\n",
    "    tree.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Observe the workings of the different parser algorithms\n",
    "\n",
    "# Top-down parser\n",
    "# - Start from “s”\n",
    "# - Generate a tree\n",
    "# - Map the tree to the terminal nodes\n",
    "\n",
    "nltk.app.rdparser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Bottom-up parser\n",
    "# - Start from the terminal nodes.\n",
    "# - Group them into phrases.\n",
    "# - Try to build up until S.\n",
    "nltk.app.srparser()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
