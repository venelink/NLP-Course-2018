{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Introduction to NLP course (2017-2018).\n",
    "\n",
    "Notebook 4: Markov Models. Hidden Markov Models. Part of speech Tagging.\n",
    "\n",
    "by Venelin Kovatchev, University of Barcelona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import section\n",
    "\n",
    "# Import nltk\n",
    "import nltk\n",
    "from nltk import bigrams, trigrams\n",
    "\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Import codecs\n",
    "import codecs\n",
    "\n",
    "# Import taggers\n",
    "from nltk import DefaultTagger, AffixTagger, UnigramTagger, BigramTagger, TrigramTagger\n",
    "from nltk import ClassifierBasedPOSTagger\n",
    "\n",
    "# Import the brown corpus\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In the first part of the notebook, we will \"train\" a very simple \n",
    "Bigram Markov Model on a dataset containing speeches by Donald \n",
    "Trump. We will use the \"model\" to generate pseudo text.\n",
    "\n",
    "The speeches were taken from https://github.com/ryanmcdermott/trump-speeches\n",
    "\n",
    "The text file is available in the campus virtual and in the github repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sentence that president Trump could have said is: – six weeks after another after – and your case known\n"
     ]
    }
   ],
   "source": [
    "# Read the corpus\n",
    "raw_corpus = codecs.open('speeches.txt','r','utf8').read()\n",
    "\n",
    "# Tokenize the corpus\n",
    "corpus = nltk.word_tokenize(raw_corpus)\n",
    "\n",
    "# Generate all bigrams in the corpus\n",
    "trump_bigr = list(nltk.bigrams(corpus))\n",
    "\n",
    "# Initialize the dummy markov model stats\n",
    "markov_stats = {}\n",
    "\n",
    "# Fill in all the counts\n",
    "for word_1, word_2 in trump_bigr:\n",
    "    # Check if there is an entry for the current word\n",
    "    if word_1 in markov_stats.keys():\n",
    "        # If it is, append the second one\n",
    "        markov_stats[word_1].append(word_2)\n",
    "        \n",
    "    # If it isn't, create it with the corresponding value\n",
    "    else:\n",
    "        markov_stats[word_1] = [word_2]\n",
    "\n",
    "# Get the first word at random\n",
    "first_word = np.random.choice(corpus)\n",
    "\n",
    "# Check if the first word is lowercase, if it is, pick another one\n",
    "while first_word.islower():\n",
    "    first_word = np.random.choice(corpus)\n",
    "    \n",
    "# Initialize the new speech variable\n",
    "new_speech = [first_word]\n",
    "\n",
    "# Generate a sentence of length 10\n",
    "for i in range(10):\n",
    "    # Get the next word by randomly getting a word from the corresponding dictionary\n",
    "    next_word = np.random.choice(markov_stats[new_speech[-1]])\n",
    "    # Append the word\n",
    "    new_speech.append(next_word)\n",
    "    \n",
    "\n",
    "    \n",
    "# Join all the words into a string\n",
    "speech_string = ' '.join(new_speech)\n",
    "# Encode in utf8\n",
    "speech_string.encode('utf-8').strip()\n",
    "\n",
    "# Print the speech\n",
    "print (u\"A sentence that president Trump could have said is: {}\".format(speech_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In the second part of this notebook we will see the different taggers built-in NLTK.\n",
    "\n",
    "We start by analyzing the content of the brown corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The first 5 words in the tokenized and tagged version are: [(u'The', u'AT'), (u'Fulton', u'NP-TL'), (u'County', u'NN-TL'), (u'Grand', u'JJ-TL'), (u'Jury', u'NN-TL')]\n",
      "\n",
      "The first 2 sentences in the sentence segmented, tokenized and tagged version are [[(u'The', u'AT'), (u'Fulton', u'NP-TL'), (u'County', u'NN-TL'), (u'Grand', u'JJ-TL'), (u'Jury', u'NN-TL'), (u'said', u'VBD'), (u'Friday', u'NR'), (u'an', u'AT'), (u'investigation', u'NN'), (u'of', u'IN'), (u\"Atlanta's\", u'NP$'), (u'recent', u'JJ'), (u'primary', u'NN'), (u'election', u'NN'), (u'produced', u'VBD'), (u'``', u'``'), (u'no', u'AT'), (u'evidence', u'NN'), (u\"''\", u\"''\"), (u'that', u'CS'), (u'any', u'DTI'), (u'irregularities', u'NNS'), (u'took', u'VBD'), (u'place', u'NN'), (u'.', u'.')], [(u'The', u'AT'), (u'jury', u'NN'), (u'further', u'RBR'), (u'said', u'VBD'), (u'in', u'IN'), (u'term-end', u'NN'), (u'presentments', u'NNS'), (u'that', u'CS'), (u'the', u'AT'), (u'City', u'NN-TL'), (u'Executive', u'JJ-TL'), (u'Committee', u'NN-TL'), (u',', u','), (u'which', u'WDT'), (u'had', u'HVD'), (u'over-all', u'JJ'), (u'charge', u'NN'), (u'of', u'IN'), (u'the', u'AT'), (u'election', u'NN'), (u',', u','), (u'``', u'``'), (u'deserves', u'VBZ'), (u'the', u'AT'), (u'praise', u'NN'), (u'and', u'CC'), (u'thanks', u'NNS'), (u'of', u'IN'), (u'the', u'AT'), (u'City', u'NN-TL'), (u'of', u'IN-TL'), (u'Atlanta', u'NP-TL'), (u\"''\", u\"''\"), (u'for', u'IN'), (u'the', u'AT'), (u'manner', u'NN'), (u'in', u'IN'), (u'which', u'WDT'), (u'the', u'AT'), (u'election', u'NN'), (u'was', u'BEDZ'), (u'conducted', u'VBN'), (u'.', u'.')]]\n",
      "\n",
      "The set of all original tags in the brown orpus is: set([u'BE', u'BEZ-HL', u'NP$', u'WQL', u'AT-TL', u'BEDZ*', u'WDT', u'JJ', u'NR-HL', u'AP$', u'RP', u'WPS+BEZ', u'JJ-NC', u'(', u'PPSS+BER', u',', u'VBN-TL-HL', u'HVD-HL', u'PPSS+BEM', u'NPS-HL', u'RB', u'FW-PP$-NC', u'JJ-HL', u'NNS', u'WRB', u'MD-TL', u'NN-NC', u'DOD*', u'NN$', u'PPLS', u')-HL', u'BEZ*', u'RB-HL', u'NNS$', u'NPS-TL', u'NNS-HL', u'FW-IN+NN-TL', u'--', u'BER-TL', u'OD', u'PP$$', u'CC-TL', u'FW-NN-TL', u'NP-TL-HL', u'AP-TL', u'PPSS+MD', u'FW-JJ', u'FW-DT', u'BER*', u'FW-WDT', u'NPS', u'DTI', u'BEN', u'BEM', u'EX+BEZ', u'HV', u'BEG', u'BED', u'HVD', u'BEZ', u'DTX', u'FW-VB-NC', u'VBZ', u'DTS', u'RB-TL', u'VB-TL', u'NNS-TL', u'FW-CC', u'CS-HL', u'NP$-TL', u'FW-CD', u'ABN-HL', u'IN-HL', u'JJT-HL', u'BED*', u'BEDZ', u'NN-TL-HL', u'PN', u'JJR-HL', u'FW-AT-TL', u'PPSS+HVD', u'VBD-HL', u'MD-HL', u'NNS-TL-HL', u'DTI-HL', u'EX', u'VBN-HL', u'NNS$-HL', u'PPSS-HL', u'MD', u'BE-HL', u'TO-TL', u'NN-HL', u'VBZ-HL', u'NR$-TL', u'DT$', u'WP$', u'MD+HV', u'TO-HL', u'PPS+BEZ', u'DT-HL', u'CD$', u'VBG', u'VBD', u'VBN-TL', u'DOZ*', u'VBN', u'DOD', u'UH-TL', u'DOZ', u'NR-TL', u'AP-HL', u'AT-HL', u'.', u'FW-AT', u'NN', u'(-HL', u'MD*-HL', u'*', u'WPS', u'WPO', u'FW-NNS', u'NP', u'JJR-NC', u'NR', u':', u'BER-HL', u'MD*', u'``', u':-HL', u'RP-HL', u'CC', u'PP$-TL', u'WDT+BEZ', u'CD-HL', u'NPS$-TL', u'CD', u'DT+BEZ', u',-HL', u'OD-HL', u'PPS+MD', u'CS', u'NN$-HL', u'NP-TL', u'QL-TL', u'DO*', u'PPS+BEZ-HL', u'VB-HL', u'DO-HL', u'HVN', u'JJT', u'JJS', u'JJR', u'HVG', u'HVZ', u'PN+HVZ', u'NNS$-TL', u'CC-HL', u'JJ-TL', u'HVZ*', u'VBG-TL', u'DO', u'FW-JJ-TL', u'FW-*', u'NP+BEZ', u'NP-HL', u'NPS$', u'NN-TL', u'PPSS', u'NR$', u\"''\", u'BER', u'FW-VB', u'PN-HL', u'CD-TL', u'BEDZ-HL', u'DT', u'VBD-TL', u'PN$', u'VB+PPO', u')', u'VBG-HL', u'PPO', u'PPL', u'PPS', u'TO', u'RB$', u'FW-IN+NN', u'UH', u'VB', u'OD-TL', u'FW-IN', u'PP$', u'RBT', u'ABL', u'RBR', u'ABN', u'AP', u'PPSS+HV', u'AT', u'JJS-TL', u'IN', u'ABX', u'*-HL', u'FW-AT-HL', u'HVD*', u\"'\", u'JJR-TL', u'RB+BEZ', u'NN$-TL', u'FW-IN-TL', u'QLP', u'IN-TL', u'FW-NN', u'FW-IN+AT-TL', u'PPS+HVZ', u'QL', u'.-HL'])\n",
      "\n",
      "The set of universal tags is: set([u'ADV', u'NOUN', u'ADP', u'PRON', u'DET', u'.', u'PRT', u'VERB', u'X', u'NUM', u'CONJ', u'ADJ'])\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all categories of the brown corpus\n",
    "brown.categories()\n",
    "\n",
    "# Get the tokenized and tagged version of the \"news\" category\n",
    "brown_twords = brown.tagged_words(categories='news')\n",
    "\n",
    "# Get the sentence segmented, tokenized, and tagged version of the \"news\" category\n",
    "brown_tsents = brown.tagged_sents(categories='news')\n",
    "\n",
    "# Print the first 5 words\n",
    "print(\"\\nThe first 5 words in the tokenized and tagged version are: {}\".format(brown_twords[:5]))\n",
    "print(\"\\nThe first 2 sentences in the sentence segmented, tokenized and tagged version are {}\".format(brown_tsents[:2]))\n",
    "\n",
    "# Get the set of all the tags in the brown corpus\n",
    "brown_tags = set([tag for (token,tag) in brown_twords])\n",
    "print(\"\\nThe set of all original tags in the brown orpus is: {}\".format(brown_tags))\n",
    "\n",
    "# Get the set of all the tags in the universal tagset\n",
    "brown_utwords = brown.tagged_words(categories='news',tagset='universal')\n",
    "universal_tags = set([tag for (token,tag) in brown_utwords])\n",
    "print(\"\\nThe set of universal tags is: {}\".format(universal_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We train and evaluate the built-in taggers:\n",
    "\n",
    "- default\n",
    "- affix\n",
    "- unigram\n",
    "- bigram\n",
    "- trigram\n",
    "- naive bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence tagged with default tagger: [('the', u'NN'), ('quick', u'NN'), ('brown', u'NN'), ('fox', u'NN'), ('jumped', u'NN'), ('over', u'NN'), ('the', u'NN'), ('lazy', u'NN'), ('dog', u'NN')]\n",
      "The accuracy of the default tagger on the corpus is: 0.13\n"
     ]
    }
   ],
   "source": [
    "# Default tagger\n",
    "\n",
    "# Get the sentence segmented and tokenized version of \"news\"\n",
    "# This is the non-part of speech tagged version that we will be tagging\n",
    "brown_sents = brown.sents(categories='news')\n",
    "\n",
    "# Get a list of all tags in the corpus\n",
    "tags = [tag for (word, tag) in brown.tagged_words(categories='news')]\n",
    "\n",
    "# Get the most frequent tag in the corpus\n",
    "most_frequent_tag = nltk.FreqDist(tags).max()\n",
    "\n",
    "# Configure a default tagger\n",
    "# The default tagger assigns the same \"default\" tag to every token in the corpus\n",
    "# We configure it to annotate with the most frequent tag\n",
    "default_tagger = nltk.DefaultTagger(most_frequent_tag)\n",
    "\n",
    "my_sent = \"the quick brown fox jumped over the lazy dog\".split()\n",
    "print(\"The sentence tagged with default tagger: {}\".format(default_tagger.tag(my_sent)))\n",
    "\n",
    "# Tag the corpus using the default tagger\n",
    "default_sents = default_tagger.tag_sents(brown_sents)\n",
    "print(\"The accuracy of the default tagger on the corpus is: {}\".format(round(default_tagger.evaluate(brown_tsents),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The first sentence, tagged with affix tagger: [(u'The', None), (u'Fulton', u'NP'), (u'County', u'NN'), (u'Grand', u'NP'), (u'Jury', None), (u'said', None), (u'Friday', u'NR'), (u'an', None), (u'investigation', u'NN'), (u'of', None), (u\"Atlanta's\", u'NP$'), (u'recent', u'NN'), (u'primary', u'JJ'), (u'election', u'NN'), (u'produced', u'VBN'), (u'``', None), (u'no', None), (u'evidence', u'NN'), (u\"''\", None), (u'that', None), (u'any', None), (u'irregularities', u'NNS'), (u'took', None), (u'place', u'NN'), (u'.', None)]\n",
      "\n",
      "The accuracy of the affix tagger on the corpus is: 0.26\n",
      "\n",
      "The first sentence, tagged with unigram tagger: [(u'The', u'AT'), (u'Fulton', None), (u'County', u'NN-TL'), (u'Grand', u'JJ-TL'), (u'Jury', u'NN-TL'), (u'said', u'VBD'), (u'Friday', u'NR'), (u'an', u'AT'), (u'investigation', u'NN'), (u'of', u'IN'), (u\"Atlanta's\", u'NP$'), (u'recent', u'JJ'), (u'primary', u'JJ'), (u'election', u'NN'), (u'produced', u'VBD'), (u'``', u'``'), (u'no', u'AT'), (u'evidence', u'NN'), (u\"''\", u\"''\"), (u'that', u'CS'), (u'any', u'DTI'), (u'irregularities', None), (u'took', u'VBD'), (u'place', u'NN'), (u'.', u'.')]\n",
      "\n",
      "The accuracy of the unigram tagger on the corpus is: 0.83\n",
      "\n",
      "The first sentence, tagged with bigram tagger: [(u'The', u'AT'), (u'Fulton', None), (u'County', None), (u'Grand', None), (u'Jury', None), (u'said', None), (u'Friday', None), (u'an', None), (u'investigation', None), (u'of', None), (u\"Atlanta's\", None), (u'recent', None), (u'primary', None), (u'election', None), (u'produced', None), (u'``', None), (u'no', None), (u'evidence', None), (u\"''\", None), (u'that', None), (u'any', None), (u'irregularities', None), (u'took', None), (u'place', None), (u'.', None)]\n",
      "\n",
      "The accuracy of the bigram tagger on the corpus is: 0.1\n",
      "\n",
      "The first sentence, tagged with trigram tagger: [(u'The', u'AT'), (u'Fulton', None), (u'County', None), (u'Grand', None), (u'Jury', None), (u'said', None), (u'Friday', None), (u'an', None), (u'investigation', None), (u'of', None), (u\"Atlanta's\", None), (u'recent', None), (u'primary', None), (u'election', None), (u'produced', None), (u'``', None), (u'no', None), (u'evidence', None), (u\"''\", None), (u'that', None), (u'any', None), (u'irregularities', None), (u'took', None), (u'place', None), (u'.', None)]\n",
      "\n",
      "The accuracy of the trigram tagger on the corpus is: 0.06\n"
     ]
    }
   ],
   "source": [
    "# For the rest of the taggers, we will split the corpus to train and test\n",
    "test_corpus = brown_tsents[:1000]\n",
    "train_corpus = brown_tsents[1000:]\n",
    "\n",
    "# Train the affix tagger\n",
    "affix_tagger = AffixTagger(train_corpus)\n",
    "\n",
    "# Tag the corpus with the affix tagger\n",
    "affix_sents = affix_tagger.tag_sents(brown_sents)\n",
    "\n",
    "# Print the first sentence and accuracy\n",
    "print(\"\\nThe first sentence, tagged with affix tagger: {}\".format(affix_sents[0]))\n",
    "print(\"\\nThe accuracy of the affix tagger on the corpus is: {}\".format(round(affix_tagger.evaluate(test_corpus),2)))\n",
    "\n",
    "# Train the unigram tagger\n",
    "unigram_tagger = UnigramTagger(train_corpus) \n",
    "\n",
    "# Tag the corpus with the unigram tagger\n",
    "uni_sents = unigram_tagger.tag_sents(brown_sents)\n",
    "\n",
    "# Print the first sentence and accuracy\n",
    "print(\"\\nThe first sentence, tagged with unigram tagger: {}\".format(uni_sents[0]))\n",
    "print(\"\\nThe accuracy of the unigram tagger on the corpus is: {}\".format(round(unigram_tagger.evaluate(test_corpus),2)))\n",
    "\n",
    "# Train the bigram tagger\n",
    "bigram_tagger = BigramTagger(train_corpus)\n",
    "\n",
    "# Tag the corpus with the bigram tagger\n",
    "bi_sents = bigram_tagger.tag_sents(brown_sents)\n",
    "\n",
    "# Print the first sentence and accuracy\n",
    "print(\"\\nThe first sentence, tagged with bigram tagger: {}\".format(bi_sents[0]))\n",
    "print(\"\\nThe accuracy of the bigram tagger on the corpus is: {}\".format(round(bigram_tagger.evaluate(test_corpus),2)))\n",
    "\n",
    "# Train the trigram tagger\n",
    "trigram_tagger = TrigramTagger(train_corpus)\n",
    "\n",
    "# Tag the corpus with the trigram tagger\n",
    "tri_sents = trigram_tagger.tag_sents(brown_sents)\n",
    "\n",
    "tri_sents = trigram_tagger.tag_sents(brown_sents)\n",
    "\n",
    "# Print the first sentence and accuracy\n",
    "print(\"\\nThe first sentence, tagged with trigram tagger: {}\".format(tri_sents[0]))\n",
    "print(\"\\nThe accuracy of the trigram tagger on the corpus is: {}\".format(round(trigram_tagger.evaluate(test_corpus),2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The first sentence, tagged with bigram taggerwith backoff: [(u'The', u'AT'), (u'Fulton', None), (u'County', u'NN-TL'), (u'Grand', u'JJ-TL'), (u'Jury', u'NN-TL'), (u'said', u'VBD'), (u'Friday', u'NR'), (u'an', u'AT'), (u'investigation', u'NN'), (u'of', u'IN'), (u\"Atlanta's\", u'NP$'), (u'recent', u'JJ'), (u'primary', u'JJ'), (u'election', u'NN'), (u'produced', u'VBD'), (u'``', u'``'), (u'no', u'AT'), (u'evidence', u'NN'), (u\"''\", u\"''\"), (u'that', u'WPS'), (u'any', u'DTI'), (u'irregularities', None), (u'took', u'VBD'), (u'place', u'NN'), (u'.', u'.')]\n",
      "\n",
      "The accuracy of the bigram tagger with backoff on the corpus is: 0.83\n"
     ]
    }
   ],
   "source": [
    "# Train the bigram tagger with backoff\n",
    "bigram_tagger_backoff = BigramTagger(train_corpus,backoff=unigram_tagger)\n",
    "\n",
    "# Tag the corpus with the bigram tagger with backoff\n",
    "bi_sents_bo = bigram_tagger_backoff.tag_sents(brown_sents)\n",
    "\n",
    "\n",
    "# Print the first sentence and accuracy\n",
    "print(\"\\nThe first sentence, tagged with bigram taggerwith backoff: {}\".format(bi_sents_bo[0]))\n",
    "print(\"\\nThe accuracy of the bigram tagger with backoff on the corpus is: {}\".format(round(bigram_tagger_backoff.evaluate(test_corpus),2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the nb tagger on the corpus is: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Train a naive bayes classifier for the tagging\n",
    "nb_tagger = ClassifierBasedPOSTagger(train=train_corpus)\n",
    "\n",
    "# Evaluate the tagger\n",
    "print(\"\\nThe accuracy of the nb tagger on the corpus is: {}\".format(round(nb_tagger.evaluate(test_corpus),2)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
