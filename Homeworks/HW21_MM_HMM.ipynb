{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Introduction to NLP course (2017-2018).\n",
    "\n",
    "Homework 2.1: Markov Models. Hidden Markov Models and Part of Speech Tagging.\n",
    "\n",
    "Objectives:\n",
    "\n",
    "1) Create a tri-gram model for generating pseudo-Trump sentences \n",
    "- load the corpus, tokenize it and obtain list of trigrams \n",
    "- define a function that obtains the counts of the \"model\" \n",
    "- define a function that generates a pseudo-sentence \n",
    "- when generating a sentence, make sure that your sentence fulfils the following requirements\n",
    "    - it is at least 5 words long\n",
    "    - the last token of the pseudo-sentence is a \".\", \"!\", or \"?\"\n",
    "    - it does not contain any other \".\", \"!\", \"?\" tokens other than the final one\n",
    "- print 5 pseudo-sentences\n",
    "\n",
    "2) Use the built-in n-gram HMM models in nltk to tag a corpus \n",
    "- load the brown corpus\n",
    "- split each category in the corpus to test and train\n",
    "- for each category in the corpus, train on the train set and evaluate on the test set the following taggers:\n",
    "    - default\n",
    "    - affix\n",
    "    - unigram\n",
    "    - bigram\n",
    "    - trigram\n",
    "    \n",
    "    Each tagger should have backoff configured on the previous tagger.\n",
    "    \n",
    "    Print the results in a table.\n",
    "    \n",
    "    \n",
    "- repeat the previous experiment using universal tagset. Print the results in a table.\n",
    "- cross evaluate between different genres (train on one category, evaluate on all the other categories). Print and compare the results\n",
    "- Only for the \"news\" portion of the corpus, compare\n",
    "    - the best berforming tagger (with backoff)\n",
    "    - the naive bayes tagger\n",
    "    \n",
    "    Compare the accuracy as well as the execution time.\n",
    "    \n",
    "    Use both the universal tagset and the full tagset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import section\n",
    "\n",
    "# Import nltk\n",
    "import nltk\n",
    "from nltk import bigrams, trigrams\n",
    "\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Import codecs\n",
    "import codecs\n",
    "\n",
    "# Import taggers\n",
    "from nltk import DefaultTagger, AffixTagger, UnigramTagger, BigramTagger, TrigramTagger\n",
    "from nltk import ClassifierBasedPOSTagger\n",
    "\n",
    "# Import the brown corpus\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Homework 2 part 1\n",
    "\n",
    "# Dummy function\n",
    "# Extend and rework\n",
    "\n",
    "def hw2_part1():\n",
    "    \n",
    "    # Trump speeches file location\n",
    "    fname = \"speeches.txt\"\n",
    "    # Read the corpus\n",
    "    raw_corpus = codecs.open(fname,'r','utf8').read()\n",
    "    \n",
    "    # Tokenize the corpus\n",
    "    corpus = nltk.word_tokenize(raw_corpus)\n",
    "\n",
    "    # Generate list of trigrams\n",
    "    \n",
    "    \n",
    "    # Initialize the \"markov model\"\n",
    "    # Preferably, you should define a function (or an object)\n",
    "    # which \"trains\" the model. You should just invoke the function here.\n",
    "\n",
    "    \n",
    "    # Fill in all the counts \n",
    "\n",
    "\n",
    "    # Generate a sentence\n",
    "    # Preferably you should define a function (or an object)\n",
    "    # which \"generates\" a sentence following the requirements (min length, ending with punctuation, etc)\n",
    "    # You should just invoke the code here\n",
    "    \n",
    "    \n",
    "    # Print the sentences\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Homework 2 part 2\n",
    "\n",
    "# Function that splits a corpus in train and test\n",
    "def split_train_test(corpus,test_size=500):\n",
    "    return corpus[test_size:], corpus[:test_size]\n",
    "\n",
    "# Dummy function\n",
    "# Extend and rework\n",
    "def hw2_part2():\n",
    "    \n",
    "    ### BROWN TAGSET\n",
    "    \n",
    "    # Split each category in the brown corpus into train and test\n",
    "    # You can define a function for that\n",
    "    \n",
    "    # For each category, train and evaluate taggers. Use backoff.\n",
    "    \n",
    "    # Default tagger (most frequent class)\n",
    "    \n",
    "    # Affix tagger\n",
    "    \n",
    "    # Unigram tagger\n",
    "    \n",
    "    # Bigram tagger\n",
    "    \n",
    "    # Trigram tagger\n",
    "    \n",
    "    # Print the statistics for all taggers and all categories\n",
    "    \n",
    "    \n",
    "    ### UNIVERSAL TAGSET\n",
    "    \n",
    "    # Split each category in the brown corpus into train and test using tagset='universal'\n",
    "    \n",
    "    # For each category, train and evaluate taggers. Use backoff.\n",
    "\n",
    "    # Default tagger (most frequent class)\n",
    "    \n",
    "    # Affix tagger\n",
    "    \n",
    "    # Unigram tagger\n",
    "    \n",
    "    # Bigram tagger\n",
    "    \n",
    "    # Trigram tagger\n",
    "    \n",
    "    # Print the statistics for all taggers and all categories with the universal tagset\n",
    "    \n",
    "    \n",
    "    ### NB classifier\n",
    "    \n",
    "    # Print the performance of the best performing n-gram tagger and the runtime (full tagset)\n",
    "    \n",
    "    # Train and evaluate nb tagger on the \"news\" category (full tagset)\n",
    "    \n",
    "    # Print the performance of the nb tagger and the runtime (full tagset)\n",
    "\n",
    "    # Print the performance of the best performing n-gram tagger and the runtime (universal tagset)\n",
    "    \n",
    "    # Train and evaluate nb tagger on the \"news\" category (universal tagset)\n",
    "    \n",
    "    # Print the performance of the nb tagger and the runtime (universal tagset)\n",
    "\n",
    "    \n",
    "    ### Cross evaluation\n",
    "    \n",
    "    # Cross-evaluate between categories (using universal tagset)\n",
    "    # Example: train on news_train, evaluate on the \"test\" of every other category\n",
    "    # Do this for all categories in the corpus\n",
    "    # Print the results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
